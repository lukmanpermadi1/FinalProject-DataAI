{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eazdKZriEzs4"
      },
      "source": [
        "##PHASE 1: DATA COLLECTING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoT1Cw5dZpEB"
      },
      "source": [
        "###1.1 INITIAL DATA EXPLORATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUJJOA94U6_W",
        "outputId": "feed47e4-7e65-4efc-9096-68429f050cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy matplotlib seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guHlT5gjHxa8",
        "outputId": "09644a26-4b42-494e-f793-c0dfe2f2fc51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/potable water/water_quality_potability.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_CZdOm3E7Sf"
      },
      "source": [
        "#PHASE 3: PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU9jb8agNk4A"
      },
      "source": [
        "##3.1 LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5VsrC8m1lsa",
        "outputId": "484d9527-f3ce-4356-d2f8-e3e6d49ccfa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dataset shape: (10000, 10)\n",
            " Features: 9\n",
            " Target: Potability\n",
            " Training set: (8000, 9)\n",
            " Test set: (2000, 9)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD DATA\n",
        "# ============================================================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/potable water/water_quality_potability.csv\")\n",
        "\n",
        "print(f\" Dataset shape: {df.shape}\")\n",
        "print(f\" Features: {df.shape[1] - 1}\")\n",
        "print(f\" Target: Potability\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(\"Potability\", axis=1)\n",
        "y = df[\"Potability\"]\n",
        "\n",
        "# Single split - langsung train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\" Training set: {X_train.shape}\")\n",
        "print(f\" Test set: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWLYuSXx1717"
      },
      "source": [
        "##3.2 HANDLE MISSING VALUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL5kywUb1_Qj",
        "outputId": "0f8485c8-53f0-42c9-c219-bf966bf03e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Missing values handled\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/potable water/imputer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "imputer = KNNImputer(n_neighbors=5)\n",
        "X_train_imputed = pd.DataFrame(\n",
        "    imputer.fit_transform(X_train),\n",
        "    columns=X_train.columns\n",
        ")\n",
        "X_test_imputed = pd.DataFrame(\n",
        "    imputer.transform(X_test),\n",
        "    columns=X_test.columns\n",
        ")\n",
        "print(f\" Missing values handled\")\n",
        "\n",
        "# Save\n",
        "joblib.dump(imputer, \"/content/drive/MyDrive/potable water/imputer.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU-jB_Jc1NG5"
      },
      "source": [
        "## 3.3 FEATURE ENGINEERING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6JJsVsvTyBC",
        "outputId": "b581c1fe-3a5e-41c2-95e5-b3102a7c9ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FEATURE ENGINEERING\n",
            "================================================================================\n",
            "Missing values in X_train_imputed: 0\n",
            "Missing values in X_test_imputed: 0\n",
            " Input data clean (tidak ada missing values)\n",
            "\n",
            "================================================================================\n",
            "\n",
            " Original features: 9\n",
            " New features created: 9\n",
            " Total features: 18\n",
            "\n",
            " Original features: 9\n",
            " New features created: 9\n",
            " Total features: 18\n",
            "Domain-based features created: 15\n",
            "Domain-based features created: 15\n",
            "\n",
            " Total features now: 33\n",
            "\n",
            " Feature Breakdown:\n",
            "  Original Numerical:      9 features\n",
            "  Data-Driven Engineered:  9 features\n",
            "  Compliance Binary:       9 features\n",
            "  Categorical:             3 features\n",
            "  Domain Engineered:       3 features\n",
            "  ----------------------------------------\n",
            "  TOTAL:                  33 features\n",
            "\n",
            "====================================================================================================\n",
            "PREPROCESSING PIPELINE\n",
            "====================================================================================================\n",
            "\n",
            "  Features before preprocessing: 33\n",
            "  Features after preprocessing:  34\n",
            "\n",
            "  Breakdown:\n",
            "    - Original (scaled):        9\n",
            "    - Data-driven (scaled):     9\n",
            "    - Compliance (binary):      9\n",
            "    - Categorical (OHE):        4\n",
            "    - Domain engineered (scaled): 3\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"FEATURE ENGINEERING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ========================================\n",
        "# STEP 1: CREATE DATA-DRIVEN FEATURES\n",
        "# ========================================\n",
        "\n",
        "def create_water_quality_features(X):\n",
        "    \"\"\"\n",
        "    Parameters: X : DataFrame\n",
        "    Preprocessed data (setelah imputation untuk missing value, sebelum handling outliers)\n",
        "    Returns: X_fe : Data original +  feature baru\n",
        "    \"\"\"\n",
        "    X_fe = X.copy()\n",
        "\n",
        "    # -----------------\n",
        "    # 1. RATIO FEATURES\n",
        "    # -----------------\n",
        "\n",
        "    # pH to hardness ratio (acidity vs mineral content)\n",
        "    # X_fe[\"ph_hardness_ratio\"] = X_fe[\"ph\"] / (X_fe[\"Hardness\"] + 1e-6)\n",
        "\n",
        "    # Solids to conductivity ratio (dissolved matter)\n",
        "    X_fe[\"solids_conductivity_ratio\"] = X_fe[\"Solids\"] / (X_fe[\"Conductivity\"] + 1e-6)\n",
        "\n",
        "    # Chloramines to turbidity ratio (disinfection effectiveness)\n",
        "    # X_fe[\"chloramines_turbidity_ratio\"] = X_fe[\"Chloramines\"] / (X_fe[\"Turbidity\"] + 1e-6)\n",
        "\n",
        "    # Organic carbon to trihalomethanes ratio (contamination indicators)\n",
        "    X_fe[\"organic_thm_ratio\"] = X_fe[\"Organic_carbon\"] / (X_fe[\"Trihalomethanes\"] + 1e-6)\n",
        "\n",
        "    # -----------------\n",
        "    # 2. COMBINED FEATURES\n",
        "    # -----------------\n",
        "\n",
        "    # pH x Hardness (water chemistry interaction)\n",
        "    # X_fe[\"ph_hardness_interaction\"] = X_fe[\"ph\"] * X_fe[\"Hardness\"]\n",
        "\n",
        "    # Chloramines x pH (disinfection effectiveness at different pH)\n",
        "    X_fe[\"chloramines_ph_interaction\"] = X_fe[\"Chloramines\"] * X_fe[\"ph\"]\n",
        "\n",
        "    # Sulfate x Conductivity (ionic content indicator)\n",
        "    X_fe[\"sulfate_conductivity_interaction\"] = X_fe[\"Sulfate\"] * X_fe[\"Conductivity\"]\n",
        "\n",
        "    # -----------------\n",
        "    # 3. POLYNOMIAL FEATURES (non-linear relationships)\n",
        "    # -----------------\n",
        "\n",
        "    # pH squared (pH has non-linear effects on water quality)\n",
        "    X_fe[\"ph_squared\"] = X_fe[\"ph\"] ** 2\n",
        "\n",
        "    # Turbidity squared (clarity impact)\n",
        "    X_fe[\"turbidity_squared\"] = X_fe[\"Turbidity\"] ** 2\n",
        "\n",
        "    # Hardness squared (mineral content impact)\n",
        "    # X_fe[\"hardness_squared\"] = X_fe[\"Hardness\"] ** 2\n",
        "\n",
        "    # -----------------\n",
        "    # 4. AGGREGATE FEATURES (summary statistics)\n",
        "    # -----------------\n",
        "\n",
        "    # Total dissolved substances indicator\n",
        "    X_fe[\"total_minerals\"] = X_fe[\"Hardness\"] + X_fe[\"Sulfate\"] + X_fe[\"Solids\"]/1000\n",
        "\n",
        "    # Total contamination indicator\n",
        "    # X_fe[\"total_contamination\"] = X_fe[\"Organic_carbon\"] + X_fe[\"Trihalomethanes\"] + X_fe[\"Turbidity\"]\n",
        "\n",
        "    # Chemical balance indicator\n",
        "    X_fe[\"chemical_balance\"] = X_fe[\"Chloramines\"] + X_fe[\"Sulfate\"] - X_fe[\"Organic_carbon\"]\n",
        "\n",
        "    # Water quality score\n",
        "    X_fe[\"quality_score\"] = (\n",
        "        X_fe[\"Chloramines\"] * 0.3 +  # disinfection\n",
        "        (10 - abs(X_fe[\"ph\"] - 7)) * 0.2 +  # pH neutrality\n",
        "        (1 / (X_fe[\"Turbidity\"] + 1)) * 0.3 +  # clarity\n",
        "        (1 / (X_fe[\"Organic_carbon\"] + 1)) * 0.2  # low contamination\n",
        "    )\n",
        "\n",
        "    print(f\"\\n Original features: {len(X.columns)}\")\n",
        "    print(f\" New features created: {len(X_fe.columns) - len(X.columns)}\")\n",
        "    print(f\" Total features: {len(X_fe.columns)}\")\n",
        "\n",
        "    return X_fe\n",
        "\n",
        "print(f\"Missing values in X_train_imputed: {X_train_imputed.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test_imputed: {X_test_imputed.isnull().sum().sum()}\")\n",
        "\n",
        "if X_train_imputed.isnull().sum().sum() > 0:\n",
        "    print(\" Input ada missing values, harus cek imputation lagi\")\n",
        "else:\n",
        "    print(\" Input data clean (tidak ada missing values)\")\n",
        "\n",
        "# Create features for train and test\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "X_train_fe = create_water_quality_features(X_train_imputed)\n",
        "X_test_fe = create_water_quality_features(X_test_imputed)\n",
        "\n",
        "# ========================================\n",
        "# STEP 2: ADD DOMAIN-BASED FEATURES\n",
        "# ========================================\n",
        "\n",
        "def add_domain_features(df):\n",
        "    df_enhanced = df.copy()\n",
        "\n",
        "    # COMPLIANCE FEATURES (Binary: 1 = compliant, 0 = not compliant)\n",
        "    df_enhanced['pH_compliant'] = ((df['ph'] >= 6.5) & (df['ph'] <= 8.5)).astype(int)\n",
        "    df_enhanced['Hardness_compliant'] = ((df['Hardness'] >= 60) & (df['Hardness'] <= 200)).astype(int)\n",
        "    df_enhanced['Solids_compliant'] = (df['Solids'] < 500).astype(int)\n",
        "    df_enhanced['Chloramines_compliant'] = (df['Chloramines'] <= 4).astype(int)\n",
        "    df_enhanced['Sulfate_compliant'] = (df['Sulfate'] < 250).astype(int)\n",
        "    df_enhanced['Conductivity_compliant'] = (df['Conductivity'] < 400).astype(int)\n",
        "    df_enhanced['Organic_carbon_compliant'] = (df['Organic_carbon'] < 2).astype(int)\n",
        "    df_enhanced['Trihalomethanes_compliant'] = (df['Trihalomethanes'] < 80).astype(int)\n",
        "    df_enhanced['Turbidity_compliant'] = (df['Turbidity'] < 5).astype(int)\n",
        "\n",
        "    # CATEGORICAL FEATURES\n",
        "    df_enhanced['pH_category'] = pd.cut(df['ph'],\n",
        "                                         bins=[0, 6.5, 8.5, 14],\n",
        "                                         labels=['acidic', 'safe', 'alkaline'])\n",
        "\n",
        "    df_enhanced['Hardness_category'] = pd.cut(df['Hardness'],\n",
        "                                               bins=[0, 60, 200, np.inf],\n",
        "                                               labels=['soft', 'optimal', 'hard'])\n",
        "\n",
        "    df_enhanced['Turbidity_category'] = pd.cut(df['Turbidity'],\n",
        "                                                bins=[0, 1, 5, np.inf],\n",
        "                                                labels=['clear', 'acceptable', 'cloudy'])\n",
        "\n",
        "    # DOMAIN ENGINEERED FEATURES\n",
        "    compliance_cols = [col for col in df_enhanced.columns if col.endswith('_compliant')]\n",
        "    df_enhanced['compliance_score'] = df_enhanced[compliance_cols].mean(axis=1)\n",
        "    df_enhanced['violations_count'] = len(compliance_cols) - df_enhanced[compliance_cols].sum(axis=1)\n",
        "\n",
        "    # Severity score (weighted by importance)\n",
        "    df_enhanced['severity_score'] = (\n",
        "        (1 - df_enhanced['pH_compliant']) * 2 +\n",
        "        (1 - df_enhanced['Turbidity_compliant']) * 2 +\n",
        "        (1 - df_enhanced['Chloramines_compliant']) * 1.5 +\n",
        "        (1 - df_enhanced['Trihalomethanes_compliant']) * 1.5 +\n",
        "        (1 - df_enhanced['Organic_carbon_compliant']) * 1 +\n",
        "        (1 - df_enhanced['Hardness_compliant']) * 0.5 +\n",
        "        (1 - df_enhanced['Solids_compliant']) * 1 +\n",
        "        (1 - df_enhanced['Sulfate_compliant']) * 1 +\n",
        "        (1 - df_enhanced['Conductivity_compliant']) * 1\n",
        "    )\n",
        "\n",
        "    print(f\"Domain-based features created: {len(df_enhanced.columns) - len(df.columns)}\")\n",
        "    return df_enhanced\n",
        "\n",
        "# Apply domain feature engineering\n",
        "X_train_complete = add_domain_features(X_train_fe)\n",
        "X_test_complete = add_domain_features(X_test_fe)\n",
        "\n",
        "print(f\"\\n Total features now: {X_train_complete.shape[1]}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 3: CATEGORIZE ALL FEATURES\n",
        "# ========================================\n",
        "\n",
        "# Original numerical features\n",
        "original_numerical = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate',\n",
        "                      'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
        "\n",
        "# Data-driven engineered features (all numerical, need scaling)\n",
        "data_driven_features = [\n",
        "    'solids_conductivity_ratio',\n",
        "    'organic_thm_ratio', 'chloramines_ph_interaction',\n",
        "    'sulfate_conductivity_interaction', 'ph_squared',\n",
        "    'total_minerals', 'turbidity_squared',\n",
        "    'chemical_balance', 'quality_score'\n",
        "]\n",
        "\n",
        "# Data WHO\n",
        "compliance_features = [col for col in X_train_complete.columns if col.endswith('_compliant')]\n",
        "categorical_features = [col for col in X_train_complete.columns if col.endswith('_category')]\n",
        "domain_engineered = ['compliance_score', 'violations_count', 'severity_score']\n",
        "\n",
        "print(f\"\\n Feature Breakdown:\")\n",
        "print(f\"  Original Numerical:     {len(original_numerical):2d} features\")\n",
        "print(f\"  Data-Driven Engineered: {len(data_driven_features):2d} features\")\n",
        "print(f\"  Compliance Binary:      {len(compliance_features):2d} features\")\n",
        "print(f\"  Categorical:            {len(categorical_features):2d} features\")\n",
        "print(f\"  Domain Engineered:      {len(domain_engineered):2d} features\")\n",
        "print(f\"  \" + \"-\"*40)\n",
        "print(f\"  TOTAL:                  {len(original_numerical) + len(data_driven_features) + len(compliance_features) + len(categorical_features) + len(domain_engineered):2d} features\")\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"PREPROCESSING PIPELINE\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# ========================================\n",
        "# STEP 4: SCALING DAN ENCODING\n",
        "# ========================================\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('original_num', StandardScaler(), original_numerical),\n",
        "        ('data_driven', StandardScaler(), data_driven_features),\n",
        "        ('compliance', 'passthrough', compliance_features),  # Already binary\n",
        "        ('categorical', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_features),\n",
        "        ('domain_eng', StandardScaler(), domain_engineered)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Fit and transform\n",
        "X_train_processed = preprocessor.fit_transform(X_train_complete)\n",
        "X_test_processed = preprocessor.transform(X_test_complete)\n",
        "\n",
        "print(f\"\\n  Features before preprocessing: {X_train_complete.shape[1]}\")\n",
        "print(f\"  Features after preprocessing:  {X_train_processed.shape[1]}\")\n",
        "print(f\"\\n  Breakdown:\")\n",
        "print(f\"    - Original (scaled):        {len(original_numerical)}\")\n",
        "print(f\"    - Data-driven (scaled):     {len(data_driven_features)}\")\n",
        "print(f\"    - Compliance (binary):      {len(compliance_features)}\")\n",
        "print(f\"    - Categorical (OHE):        {X_train_processed.shape[1] - len(original_numerical) - len(data_driven_features) - len(compliance_features) - len(domain_engineered)}\")\n",
        "print(f\"    - Domain engineered (scaled): {len(domain_engineered)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_papBCM93Pgv"
      },
      "source": [
        "##3.3 HANDLE OUTLIERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlbPtKybAfPp",
        "outputId": "33333874-e9ca-4d6c-a2d1-3794d6968f56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "OUTLIER HANDLING STRATEGY\n",
            "====================================================================================================\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Data Integrity Check\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            " Training features (X_train_complete):  (8000, 33)\n",
            "Test features (X_test_complete):      (2000, 33)\n",
            "Training labels (y_train):            (8000,)\n",
            "Test labels (y_test):                 (2000,)\n",
            "\n",
            " Missing values in X_train_complete:   0\n",
            "Missing values in X_test_complete:    0\n",
            "\n",
            " Class distribution in y_train:\n",
            "            percentage\n",
            "Potability            \n",
            "0                  0.5\n",
            "1                  0.5\n",
            "\n",
            " Class distribution in y_test:\n",
            "            percentage\n",
            "Potability            \n",
            "0                  0.5\n",
            "1                  0.5\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Outlier Statistics (IQR Method - Information Only)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            " Outliers detected (but KEPT in dataset):\n",
            "Feature                     Outlier Count   Percentage\n",
            "-------------------------------------------------------\n",
            "ph                                   1354       16.93%\n",
            "Hardness                             1340       16.75%\n",
            "Solids                               1313       16.41%\n",
            "Chloramines                          1327       16.59%\n",
            "Sulfate                              1334       16.68%\n",
            "Conductivity                         1383       17.29%\n",
            "Organic_carbon                       1372       17.15%\n",
            "Trihalomethanes                      1330       16.62%\n",
            "Turbidity                            1365       17.06%\n",
            "-------------------------------------------------------\n",
            "\n",
            "Total rows with outliers:            1627       20.34%\n",
            "Rows kept for training:              8000      100.00%\n",
            "\n",
            "====================================================================================================\n",
            "PREPROCESSED DATA STATUS\n",
            "====================================================================================================\n",
            "\n",
            "  X_train_processed shape: (8000, 34)\n",
            "  X_test_processed shape:  (2000, 34)\n",
            "\n",
            "  Features breakdown:\n",
            "    - Before preprocessing: 33 features\n",
            "    - After preprocessing:  34 features\n",
            "    - Samples in training:  8000 samples\n",
            "    - Samples in test:      2000 samples\n",
            "\n",
            "====================================================================================================\n",
            " DATA READY FOR MODELING\n",
            "====================================================================================================\n",
            "\n",
            " Dataset Summary:\n",
            "  strategy: keep_all_outliers\n",
            "  X_train_shape: (8000, 34)\n",
            "  X_test_shape: (2000, 34)\n",
            "  features_before_preprocessing: 33\n",
            "  features_after_preprocessing: 34\n",
            "  outlier_rows_in_train: 1627\n",
            "  outlier_percentage: 20.3375\n",
            "  total_samples_train: 8000\n",
            "  total_samples_test: 2000\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# OUTLIER HANDLING DECISION\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"OUTLIER HANDLING STRATEGY\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# ==============================================================================\n",
        "# VERIFY DATA INTEGRITY\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"-\"*100)\n",
        "print(\"Data Integrity Check\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Reset index\n",
        "X_train_complete = X_train_complete.reset_index(drop=True)\n",
        "X_test_complete = X_test_complete.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n Training features (X_train_complete):  {X_train_complete.shape}\")\n",
        "print(f\"Test features (X_test_complete):      {X_test_complete.shape}\")\n",
        "print(f\"Training labels (y_train):            {y_train.shape}\")\n",
        "print(f\"Test labels (y_test):                 {y_test.shape}\")\n",
        "\n",
        "print(f\"\\n Missing values in X_train_complete:   {X_train_complete.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test_complete:    {X_test_complete.isnull().sum().sum()}\")\n",
        "\n",
        "print(f\"\\n Class distribution in y_train:\")\n",
        "print(y_train.value_counts(normalize=True).to_frame('percentage').round(4))\n",
        "\n",
        "print(f\"\\n Class distribution in y_test:\")\n",
        "print(y_test.value_counts(normalize=True).to_frame('percentage').round(4))\n",
        "\n",
        "# ==============================================================================\n",
        "# OUTLIER STATISTICS (For Information Only)\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"-\"*100)\n",
        "print(\"Outlier Statistics (IQR Method - Information Only)\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Original features for outlier detection\n",
        "original_features = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate',\n",
        "                     'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
        "\n",
        "def detect_outliers_iqr(df, column):\n",
        "    \"\"\"Detect outliers using IQR method\"\"\"\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "    return len(outliers), (len(outliers) / len(df)) * 100\n",
        "\n",
        "print(\"\\n Outliers detected (but KEPT in dataset):\")\n",
        "print(f\"{'Feature':<25} {'Outlier Count':>15} {'Percentage':>12}\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "total_outlier_rows = 0\n",
        "for feature in original_features:\n",
        "    count, pct = detect_outliers_iqr(X_train_complete, feature)\n",
        "    print(f\"{feature:<25} {count:>15} {pct:>11.2f}%\")\n",
        "\n",
        "outlier_mask = pd.Series([False] * len(X_train_complete))\n",
        "for feature in original_features:\n",
        "    Q1 = X_train_complete[feature].quantile(0.25)\n",
        "    Q3 = X_train_complete[feature].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outlier_mask |= (X_train_complete[feature] < lower_bound) | (X_train_complete[feature] > upper_bound)\n",
        "\n",
        "total_outlier_rows = outlier_mask.sum()\n",
        "outlier_row_pct = (total_outlier_rows / len(X_train_complete)) * 100\n",
        "\n",
        "print(\"-\" * 55)\n",
        "print(f\"\\n{'Total rows with outliers:':<25} {total_outlier_rows:>15} {outlier_row_pct:>11.2f}%\")\n",
        "print(f\"{'Rows kept for training:':<25} {len(X_train_complete):>15} {'100.00%':>12}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# PREPROCESSED DATA STATUS\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"PREPROCESSED DATA STATUS\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "print(f\"\\n  X_train_processed shape: {X_train_processed.shape}\")\n",
        "print(f\"  X_test_processed shape:  {X_test_processed.shape}\")\n",
        "print(f\"\\n  Features breakdown:\")\n",
        "print(f\"    - Before preprocessing: {X_train_complete.shape[1]} features\")\n",
        "print(f\"    - After preprocessing:  {X_train_processed.shape[1]} features\")\n",
        "print(f\"    - Samples in training:  {X_train_processed.shape[0]} samples\")\n",
        "print(f\"    - Samples in test:      {X_test_processed.shape[0]} samples\")\n",
        "\n",
        "# ==============================================================================\n",
        "# FINAL CONFIRMATION\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" DATA READY FOR MODELING\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Optional: Store dataset info untuk tracking\n",
        "dataset_info = {\n",
        "    'strategy': 'keep_all_outliers',\n",
        "    'X_train_shape': X_train_processed.shape,\n",
        "    'X_test_shape': X_test_processed.shape,\n",
        "    'features_before_preprocessing': X_train_complete.shape[1],\n",
        "    'features_after_preprocessing': X_train_processed.shape[1],\n",
        "    'outlier_rows_in_train': total_outlier_rows,\n",
        "    'outlier_percentage': outlier_row_pct,\n",
        "    'total_samples_train': len(X_train_processed),\n",
        "    'total_samples_test': len(X_test_processed)\n",
        "}\n",
        "\n",
        "print(\"\\n Dataset Summary:\")\n",
        "for key, value in dataset_info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8BK4H5aok9E"
      },
      "source": [
        "SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q099nBsokcs",
        "outputId": "f7496165-04a4-42f8-9582-7639131cb086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "APPLYING SMOTE + TOMEK LINKS\n",
            "====================================================================================================\n",
            "Before resampling:\n",
            "  Class 0: 4000\n",
            "  Class 1: 4000\n",
            "\n",
            "After SMOTE+Tomek:\n",
            "  Class 0: 3702\n",
            "  Class 1: 3702\n"
          ]
        }
      ],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"APPLYING SMOTE + TOMEK LINKS\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "print(f\"Before resampling:\")\n",
        "print(f\"  Class 0: {(y_train == 0).sum()}\")\n",
        "print(f\"  Class 1: {(y_train == 1).sum()}\")\n",
        "\n",
        "smote_tomek = SMOTETomek(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train_processed, y_train)\n",
        "\n",
        "print(f\"\\nAfter SMOTE+Tomek:\")\n",
        "print(f\"  Class 0: {(y_train_resampled == 0).sum()}\")\n",
        "print(f\"  Class 1: {(y_train_resampled == 1).sum()}\")\n",
        "\n",
        "# Update sample weights\n",
        "sample_weights = compute_sample_weight('balanced', y=y_train_resampled)\n",
        "scale_pos_weight = (y_train_resampled == 0).sum() / (y_train_resampled == 1).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-djdzaKzQ1ki"
      },
      "source": [
        "##3.5 SAVE PREPROCESSED DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtprpPIVQ7Tr",
        "outputId": "e9adb1e3-b413-42bb-9c68-5337de76dcf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SAVING PREPROCESSED DATA\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SAVING PREPROCESSED DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/potable water/outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "X_train_processed_df = pd.DataFrame(X_train_processed)\n",
        "X_test_processed_df = pd.DataFrame(X_test_processed)\n",
        "\n",
        "# Save training data\n",
        "X_train_processed_df.to_csv(f\"{output_dir}/X_train_processed.csv\", index=False)\n",
        "y_train.to_csv(f\"{output_dir}/y_train_resampled.csv\", index=False, header=True)\n",
        "\n",
        "# Save test data\n",
        "X_test_processed_df.to_csv(f\"{output_dir}/X_test_processed.csv\", index=False)\n",
        "y_test.to_csv(f\"{output_dir}/y_test_processed.csv\", index=False, header=True)\n",
        "\n",
        "# Save preprocessing objects\n",
        "joblib.dump(imputer, f\"{output_dir}/imputer.pkl\")\n",
        "\n",
        "feature_info = {\n",
        "    \"original_features\": list(X_train_imputed.columns),\n",
        "    \"new_features\": [col for col in X_train_fe.columns if col not in X_train_imputed.columns],\n",
        "    \"all_features\": [f'feature_{i}' for i in range(X_train_processed.shape[1])], # Placeholder names\n",
        "    \"total_features\": X_train_processed.shape[1]\n",
        "}\n",
        "\n",
        "import json\n",
        "with open(f\"{output_dir}/feature_info.json\", \"w\") as f:\n",
        "    json.dump(feature_info, f, indent=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoWfuajtUKoP"
      },
      "source": [
        "#PHASE 4: MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6z0-rYn1s_O",
        "outputId": "0e734ae5-4b36-4018-9572-6af4ab9a44e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "BASELINE MODEL TRAINING - RANDOM FOREST\n",
            "====================================================================================================\n",
            "\n",
            " Training set X_train_processed: (8000, 34)\n",
            " Training set X_train_resampled: (7404, 34)\n",
            " Test set: (2000, 34)\n",
            " Features: 34\n",
            "\n",
            " Target distribution (y_train_resampled):\n",
            "    Class 0 (Not Potable): 3702 (50.0%)\n",
            "    Class 1 (Potable): 3702 (50.0%)\n",
            "\n",
            " Target distribution (y_test):\n",
            "  Class 0 (Not Potable): 1000 (50.0%)\n",
            "  Class 1 (Potable):     1000 (50.0%)\n",
            "\n",
            "Class imbalance handling:\n",
            "  Scale pos weight (XGBoost) for resampled data: 1.00\n",
            "  Sample weights for resampled data calculated\n",
            "\n",
            "====================================================================================================\n",
            "TRAINING BASELINE MODELS\n",
            "====================================================================================================\n",
            "\n",
            "Training baseline models with 5-fold cross-validation\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            " Random Forest...\n",
            "  Running 5-fold cross-validation...\n",
            "  CV ROC-AUC: 0.9527 (+/- 0.0108)\n",
            "  Individual folds: ['0.9614', '0.9531', '0.9518', '0.9528', '0.9443']\n",
            "  OOB Score:      0.8790\n",
            "  Test Accuracy:  0.8490\n",
            "  Test ROC-AUC:   0.9345\n",
            "  Test F1-Score:  0.8487\n",
            "  Class 1 Recall: 0.8070 (Potable detection)\n",
            "  Training Time:  22.11s\n",
            "\n",
            "====================================================================================================\n",
            " RESULTS SUMMARY \n",
            "====================================================================================================\n",
            "\n",
            "         Model      CV ROC-AUC  Test Accuracy  Test Precision  Test Recall  Test F1  Test ROC-AUC  Train Time (s)\n",
            "Random Forest 0.9527 Â± 0.0054          0.849         0.85148        0.849 0.848733      0.934548        22.10688\n",
            "\n",
            " Best Model: Random Forest\n",
            "   CV ROC-AUC:   0.9527\n",
            "   Test ROC-AUC: 0.9345\n",
            "\n",
            "====================================================================================================\n",
            " DETAILED PER-CLASS PERFORMANCE \n",
            "====================================================================================================\n",
            "\n",
            "================================================================================\n",
            "Random Forest\n",
            "================================================================================\n",
            "\n",
            "Overall Metrics:\n",
            "  CV ROC-AUC:     0.9527 (+/- 0.0108)\n",
            "  Test Accuracy:  0.8490\n",
            "  Test F1:        0.8487\n",
            "  Test ROC-AUC:   0.9345\n",
            "\n",
            "Class 0 (Not Potable):\n",
            "  Precision: 0.8220\n",
            "  Recall:    0.8910\n",
            "  F1-Score:  0.8551\n",
            "\n",
            "Class 1 (Potable):\n",
            "  Precision: 0.8810\n",
            "  Recall:    0.8070\n",
            "  F1-Score:  0.8424\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Not Potable     0.8220    0.8910    0.8551      1000\n",
            "     Potable     0.8810    0.8070    0.8424      1000\n",
            "\n",
            "    accuracy                         0.8490      2000\n",
            "   macro avg     0.8515    0.8490    0.8487      2000\n",
            "weighted avg     0.8515    0.8490    0.8487      2000\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            " PER-CLASS F1-SCORE COMPARISON \n",
            "====================================================================================================\n",
            "\n",
            "         Model CV ROC-AUC Precision (0) Recall (0) F1 (0) Precision (1) Recall (1) F1 (1) Test ROC-AUC\n",
            "Random Forest     0.9527        0.8220     0.8910 0.8551        0.8810     0.8070 0.8424       0.9345\n",
            "\n",
            "====================================================================================================\n",
            " FEATURE IMPORTANCE ANALYSIS \n",
            "====================================================================================================\n",
            "\n",
            "Top 10 Most Important Features for Random Forest:\n",
            "                         feature  importance\n",
            "       solids_conductivity_ratio    0.190491\n",
            "                          Solids    0.157197\n",
            "      chloramines_ph_interaction    0.082065\n",
            "                     Chloramines    0.059045\n",
            "               turbidity_squared    0.051928\n",
            "                       Turbidity    0.051408\n",
            "sulfate_conductivity_interaction    0.043190\n",
            "               organic_thm_ratio    0.042363\n",
            "                         Sulfate    0.037045\n",
            "                   quality_score    0.036973\n",
            "\n",
            "Bottom 5 Least Important Features:\n",
            "                 feature  importance\n",
            "     Turbidity_compliant    0.000279\n",
            "       Sulfate_compliant    0.000199\n",
            "   Chloramines_compliant    0.000163\n",
            "Organic_carbon_compliant    0.000000\n",
            "        Solids_compliant    0.000000\n",
            "\n",
            "Feature Importance Statistics:\n",
            "  Mean importance: 0.029412\n",
            "  Median importance: 0.021097\n",
            "  Features with >5% importance: 6\n",
            "  Features with <1% importance: 16\n",
            "\n",
            "====================================================================================================\n",
            "TRAINING COMPLETE\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Models\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder # Import OneHotEncoder for feature name extraction\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*100)\n",
        "print(\"BASELINE MODEL TRAINING - RANDOM FOREST\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "print(f\"\\n Training set X_train_processed: {X_train_processed.shape}\")\n",
        "print(f\" Training set X_train_resampled: {X_train_resampled.shape}\")\n",
        "print(f\" Test set: {X_test_processed.shape}\")\n",
        "print(f\" Features: {X_train_resampled.shape[1]}\")\n",
        "\n",
        "print(f\"\\n Target distribution (y_train_resampled):\")\n",
        "print(f\"    Class 0 (Not Potable): {(y_train_resampled == 0).sum()} ({(y_train_resampled == 0).sum()/len(y_train_resampled)*100:.1f}%)\")\n",
        "print(f\"    Class 1 (Potable): {(y_train_resampled == 1).sum()} ({(y_train_resampled == 1).sum()/len(y_train_resampled)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n Target distribution (y_test):\")\n",
        "print(f\"  Class 0 (Not Potable): {(y_test == 0).sum():4d} ({(y_test == 0).sum()/len(y_test)*100:.1f}%)\")\n",
        "print(f\"  Class 1 (Potable):     {(y_test == 1).sum():4d} ({(y_test == 1).sum()/len(y_test)*100:.1f}%)\")\n",
        "\n",
        "# ==============================================================================\n",
        "# BASELINE MODEL\n",
        "# ==============================================================================\n",
        "\n",
        "sample_weights = compute_sample_weight('balanced', y=y_train_resampled)\n",
        "scale_pos_weight = (y_train_resampled == 0).sum() / (y_train_resampled == 1).sum()\n",
        "\n",
        "print(f\"\\nClass imbalance handling:\")\n",
        "print(f\"  Scale pos weight (XGBoost) for resampled data: {scale_pos_weight:.2f}\")\n",
        "print(f\"  Sample weights for resampled data calculated\")\n",
        "\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=15,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        max_features='sqrt',\n",
        "        max_samples=0.8,             # Bootstrap sample size (80% dari data)\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        class_weight='balanced',\n",
        "        oob_score=True\n",
        "    ),\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"TRAINING BASELINE MODELS\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Store results\n",
        "baseline_results = {}\n",
        "\n",
        "# Cross-validation setup\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\nTraining baseline models with 5-fold cross-validation\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n {name}...\")\n",
        "\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Perform cross-validation\n",
        "        print(f\"  Running 5-fold cross-validation...\")\n",
        "        cv_scores = cross_val_score(\n",
        "            model, X_train_resampled, y_train_resampled,\n",
        "            cv=cv,\n",
        "            scoring='roc_auc',\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        print(f\"  CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "        print(f\"  Individual folds: {[f'{score:.4f}' for score in cv_scores]}\")\n",
        "\n",
        "        # Train full training data\n",
        "        if name in ['Gradient Boosting', 'AdaBoost']:\n",
        "            model.fit(X_train_resampled, y_train_resampled, sample_weight=sample_weights)\n",
        "        else:\n",
        "            model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "        train_time = time.time() - start_time\n",
        "\n",
        "        if hasattr(model, 'oob_score_'):\n",
        "            print(f\"  OOB Score:      {model.oob_score_:.4f}\")\n",
        "\n",
        "        # Test set predictions\n",
        "        y_pred = model.predict(X_test_processed)\n",
        "\n",
        "        # ROC-AUC\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
        "            test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        else:\n",
        "            y_pred_proba = None\n",
        "            test_roc_auc = np.nan\n",
        "\n",
        "        test_accuracy = accuracy_score(y_test, y_pred)\n",
        "        test_precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        test_recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        test_f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "        # PER-CLASS METRICS\n",
        "        test_precision_class0 = precision_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
        "        test_recall_class0 = recall_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
        "        test_f1_class0 = f1_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
        "\n",
        "        test_precision_class1 = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "        test_recall_class1 = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "        test_f1_class1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "        # Store results\n",
        "        baseline_results[name] = {\n",
        "            'cv_roc_auc_mean': cv_scores.mean(),\n",
        "            'cv_roc_auc_std': cv_scores.std(),\n",
        "            'cv_scores': cv_scores,\n",
        "            'test_accuracy': test_accuracy,\n",
        "            'test_precision': test_precision,\n",
        "            'test_recall': test_recall,\n",
        "            'test_f1': test_f1,\n",
        "            'test_roc_auc': test_roc_auc,\n",
        "\n",
        "            # Per-class metrics\n",
        "            'precision_class0': test_precision_class0,\n",
        "            'recall_class0': test_recall_class0,\n",
        "            'f1_class0': test_f1_class0,\n",
        "            'precision_class1': test_precision_class1,\n",
        "            'recall_class1': test_recall_class1,\n",
        "            'f1_class1': test_f1_class1,\n",
        "\n",
        "            'y_pred': y_pred,\n",
        "            'y_pred_proba': y_pred_proba,\n",
        "            'train_time': train_time,\n",
        "            'model': model\n",
        "        }\n",
        "\n",
        "        print(f\"  Test Accuracy:  {test_accuracy:.4f}\")\n",
        "        print(f\"  Test ROC-AUC:   {test_roc_auc:.4f}\")\n",
        "        print(f\"  Test F1-Score:  {test_f1:.4f}\")\n",
        "        print(f\"  Class 1 Recall: {test_recall_class1:.4f} (Potable detection)\")\n",
        "        print(f\"  Training Time:  {train_time:.2f}s\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "# ==============================================================================\n",
        "# RESULTS SUMMARY\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" RESULTS SUMMARY \")\n",
        "print(\"=\"*100)\n",
        "\n",
        "if baseline_results:\n",
        "    results_df = pd.DataFrame({\n",
        "        'Model': list(baseline_results.keys()),\n",
        "        'CV ROC-AUC': [f\"{baseline_results[m]['cv_roc_auc_mean']:.4f} \\u00b1 {baseline_results[m]['cv_roc_auc_std']:.4f}\"\n",
        "                       for m in baseline_results],\n",
        "        'Test Accuracy': [baseline_results[m]['test_accuracy'] for m in baseline_results],\n",
        "        'Test Precision': [baseline_results[m]['test_precision'] for m in baseline_results],\n",
        "        'Test Recall': [baseline_results[m]['test_recall'] for m in baseline_results],\n",
        "        'Test F1': [baseline_results[m]['test_f1'] for m in baseline_results],\n",
        "        'Test ROC-AUC': [baseline_results[m]['test_roc_auc'] for m in baseline_results],\n",
        "        'Train Time (s)': [baseline_results[m]['train_time'] for m in baseline_results]\n",
        "    })\n",
        "\n",
        "    # Sort by Test ROC-AUC\n",
        "    results_df = results_df.sort_values('Test ROC-AUC', ascending=False)\n",
        "\n",
        "    print(\"\\n\", results_df.to_string(index=False))\n",
        "\n",
        "    # Identify best model\n",
        "    best_model_name = results_df.iloc[0]['Model']\n",
        "    best_roc_auc = baseline_results[best_model_name]['test_roc_auc']\n",
        "    best_cv_roc_auc = baseline_results[best_model_name]['cv_roc_auc_mean']\n",
        "\n",
        "    print(f\"\\n Best Model: {best_model_name}\")\n",
        "    print(f\"   CV ROC-AUC:   {best_cv_roc_auc:.4f}\")\n",
        "    print(f\"   Test ROC-AUC: {best_roc_auc:.4f}\")\n",
        "\n",
        "    # ==============================================================================\n",
        "    # DETAILED PER-CLASS RESULTS\n",
        "    # ==============================================================================\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\" DETAILED PER-CLASS PERFORMANCE \")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    for idx, row in results_df.iterrows():\n",
        "        model_name = row['Model']\n",
        "        metrics = baseline_results[model_name]\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"{model_name}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Overall metrics\n",
        "        print(f\"\\nOverall Metrics:\")\n",
        "        print(f\"  CV ROC-AUC:     {metrics['cv_roc_auc_mean']:.4f} (+/- {metrics['cv_roc_auc_std']*2:.4f})\")\n",
        "        print(f\"  Test Accuracy:  {metrics['test_accuracy']:.4f}\")\n",
        "        print(f\"  Test F1:        {metrics['test_f1']:.4f}\")\n",
        "        print(f\"  Test ROC-AUC:   {metrics['test_roc_auc']:.4f}\")\n",
        "\n",
        "        # Class-specific breakdown\n",
        "        print(f\"\\nClass 0 (Not Potable):\")\n",
        "        print(f\"  Precision: {metrics['precision_class0']:.4f}\")\n",
        "        print(f\"  Recall:    {metrics['recall_class0']:.4f}\")\n",
        "        print(f\"  F1-Score:  {metrics['f1_class0']:.4f}\")\n",
        "\n",
        "        print(f\"\\nClass 1 (Potable):\")\n",
        "        print(f\"  Precision: {metrics['precision_class1']:.4f}\")\n",
        "        print(f\"  Recall:    {metrics['recall_class1']:.4f}\")\n",
        "        print(f\"  F1-Score:  {metrics['f1_class1']:.4f}\")\n",
        "\n",
        "        # Classification report\n",
        "        print(f\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, metrics['y_pred'],\n",
        "                                   target_names=['Not Potable', 'Potable'],\n",
        "                                   digits=4))\n",
        "\n",
        "    # ==============================================================================\n",
        "    # PER-CLASS COMPARISON TABLE\n",
        "    # ==============================================================================\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\" PER-CLASS F1-SCORE COMPARISON \")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Model': list(baseline_results.keys()),\n",
        "        'CV ROC-AUC': [f\"{baseline_results[m]['cv_roc_auc_mean']:.4f}\" for m in baseline_results],\n",
        "        'Precision (0)': [f\"{baseline_results[m]['precision_class0']:.4f}\" for m in baseline_results],\n",
        "        'Recall (0)': [f\"{baseline_results[m]['recall_class0']:.4f}\" for m in baseline_results],\n",
        "        'F1 (0)': [f\"{baseline_results[m]['f1_class0']:.4f}\" for m in baseline_results],\n",
        "        'Precision (1)': [f\"{baseline_results[m]['precision_class1']:.4f}\" for m in baseline_results],\n",
        "        'Recall (1)': [f\"{baseline_results[m]['recall_class1']:.4f}\" for m in baseline_results],\n",
        "        'F1 (1)': [f\"{baseline_results[m]['f1_class1']:.4f}\" for m in baseline_results],\n",
        "        'Test ROC-AUC': [f\"{baseline_results[m]['test_roc_auc']:.4f}\" for m in baseline_results],\n",
        "    })\n",
        "\n",
        "    # Sort by Test ROC-AUC\n",
        "    roc_scores = [baseline_results[m]['test_roc_auc'] for m in baseline_results]\n",
        "    comparison_df['_sort'] = roc_scores\n",
        "    comparison_df = comparison_df.sort_values('_sort', ascending=False)\n",
        "    comparison_df = comparison_df.drop('_sort', axis=1)\n",
        "\n",
        "    print(\"\\n\", comparison_df.to_string(index=False))\n",
        "\n",
        "    # ==============================================================================\n",
        "    # FEATURE IMPORTANCE ANALYSIS\n",
        "    # ==============================================================================\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\" FEATURE IMPORTANCE ANALYSIS \")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    best_model = baseline_results[best_model_name]['model']\n",
        "\n",
        "    if hasattr(best_model, 'feature_importances_'):\n",
        "\n",
        "        def get_processed_feature_names(preprocessor, input_df_columns):\n",
        "            output_feature_names = []\n",
        "            for name, transformer, features_orig in preprocessor.transformers_:\n",
        "                if transformer == 'passthrough':\n",
        "                    output_feature_names.extend(features_orig)\n",
        "                elif hasattr(transformer, 'get_feature_names_out'):\n",
        "                    if isinstance(transformer, OneHotEncoder):\n",
        "                        output_feature_names.extend(transformer.get_feature_names_out(features_orig))\n",
        "                    else:\n",
        "                        output_feature_names.extend(features_orig)\n",
        "                else:\n",
        "                    output_feature_names.extend(features_orig)\n",
        "            return output_feature_names\n",
        "\n",
        "        feature_names = get_processed_feature_names(preprocessor, X_train_complete.columns)\n",
        "\n",
        "        # Create feature importance dataframe\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'importance': best_model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        print(f\"\\nTop 10 Most Important Features for {best_model_name}:\")\n",
        "        print(feature_importance.head(10).to_string(index=False))\n",
        "\n",
        "        print(f\"\\nBottom 5 Least Important Features:\")\n",
        "        print(feature_importance.tail(5).to_string(index=False))\n",
        "\n",
        "        # Summary stats\n",
        "        print(f\"\\nFeature Importance Statistics:\")\n",
        "        print(f\"  Mean importance: {feature_importance['importance'].mean():.6f}\")\n",
        "        print(f\"  Median importance: {feature_importance['importance'].median():.6f}\")\n",
        "        print(f\"  Features with >5% importance: {(feature_importance['importance'] > 0.05).sum()}\")\n",
        "        print(f\"  Features with <1% importance: {(feature_importance['importance'] < 0.01).sum()}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo models were successfully trained. 'baseline_results' is empty.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"TRAINING COMPLETE\")\n",
        "print(\"=\"*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GEN-NL0ZBbC"
      },
      "source": [
        "#PHASE 5: HYPERPARAMETER TUNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yji3UD-m3zeO",
        "outputId": "5efaeb72-75f8-4642-de22-30e60e4402a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "HYPERPARAMETER TUNING - RANDOM FOREST\n",
            "====================================================================================================\n",
            "\n",
            "Baseline Performance:\n",
            "  CV ROC-AUC:   0.9527\n",
            "  Test ROC-AUC: 0.9345\n",
            "\n",
            "Parameter Grid:\n",
            "  n_estimators: [150, 200]\n",
            "  max_depth: [10, 20, None]\n",
            "  min_samples_split: [2, 5]\n",
            "  min_samples_leaf: [1, 2]\n",
            "  max_features: ['sqrt', 'log2']\n",
            "  max_samples: [0.7, 0.8]\n",
            "\n",
            "Total parameter combinations: 96\n",
            "Total fits (5-fold CV): 480\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "\n",
            "Grid Search completed in 1216.93s (20.28 minutes)\n",
            "\n",
            "====================================================================================================\n",
            " TUNING RESULTS \n",
            "====================================================================================================\n",
            "\n",
            "Best Parameters Found:\n",
            "  max_depth: None\n",
            "  max_features: sqrt\n",
            "  max_samples: 0.8\n",
            "  min_samples_leaf: 1\n",
            "  min_samples_split: 5\n",
            "  n_estimators: 200\n",
            "\n",
            "Best CV ROC-AUC: 0.9536\n",
            "\n",
            "Calculating CV F1 score...\n",
            "  CV F1 (mean Â± std): 0.8812 Â± 0.0069\n",
            "\n",
            "Evaluating tuned model on test set...\n",
            "\n",
            "Tuned Model Performance:\n",
            "  CV ROC-AUC:     0.9536\n",
            "  CV F1:          0.8812\n",
            "  Test Accuracy:  0.8490\n",
            "  Test Precision: 0.8509\n",
            "  Test Recall:    0.8490\n",
            "  Test F1:        0.8488\n",
            "  Test ROC-AUC:   0.9337\n",
            "  OOB Score:      0.8793\n",
            "\n",
            "====================================================================================================\n",
            " BASELINE VS TUNED MODEL COMPARISON \n",
            "====================================================================================================\n",
            "\n",
            "         Metric Baseline  Tuned Improvement\n",
            "    CV ROC-AUC   0.9527 0.9536      0.0009\n",
            " Test Accuracy   0.8490 0.8490      0.0000\n",
            "Test Precision   0.8515 0.8509     -0.0006\n",
            "   Test Recall   0.8490 0.8490      0.0000\n",
            "       Test F1   0.8487 0.8488      0.0001\n",
            "  Test ROC-AUC   0.9345 0.9337     -0.0008\n",
            "     OOB Score   0.8790 0.8793      0.0003\n",
            "\n",
            "====================================================================================================\n",
            " PER-CLASS PERFORMANCE COMPARISON \n",
            "====================================================================================================\n",
            "\n",
            "           Class    Metric Baseline  Tuned Improvement\n",
            "Not Potable (0) Precision   0.8220 0.8250      0.0030\n",
            "Not Potable (0)    Recall   0.8910 0.8860     -0.0050\n",
            "Not Potable (0)  F1-Score   0.8551 0.8544     -0.0007\n",
            "    Potable (1) Precision   0.8810 0.8769     -0.0041\n",
            "    Potable (1)    Recall   0.8070 0.8120      0.0050\n",
            "    Potable (1)  F1-Score   0.8424 0.8432      0.0008\n",
            "\n",
            "====================================================================================================\n",
            " TUNED MODEL - CLASSIFICATION REPORT \n",
            "====================================================================================================\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " Not Potable     0.8250    0.8860    0.8544      1000\n",
            "     Potable     0.8769    0.8120    0.8432      1000\n",
            "\n",
            "    accuracy                         0.8490      2000\n",
            "   macro avg     0.8509    0.8490    0.8488      2000\n",
            "weighted avg     0.8509    0.8490    0.8488      2000\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            " TOP 10 PARAMETER COMBINATIONS \n",
            "====================================================================================================\n",
            "\n",
            "  rank_test_score  mean_test_score  std_test_score  param_n_estimators param_max_depth  param_min_samples_split  param_min_samples_leaf param_max_features  param_max_samples\n",
            "               1         0.953574        0.005040                 200            None                        5                       1               log2                0.8\n",
            "               1         0.953574        0.005040                 200            None                        5                       1               sqrt                0.8\n",
            "               3         0.953508        0.005034                 150            None                        5                       1               log2                0.8\n",
            "               4         0.953508        0.005034                 150            None                        5                       1               sqrt                0.8\n",
            "               5         0.953485        0.004955                 200              20                        5                       1               sqrt                0.8\n",
            "               6         0.953485        0.004955                 200              20                        5                       1               log2                0.8\n",
            "               7         0.953476        0.004782                 200              20                        2                       1               sqrt                0.7\n",
            "               7         0.953476        0.004782                 200              20                        2                       1               log2                0.7\n",
            "               9         0.953322        0.004987                 150              20                        5                       1               sqrt                0.8\n",
            "              10         0.953322        0.004987                 150              20                        5                       1               log2                0.8\n",
            "\n",
            "====================================================================================================\n",
            " FEATURE IMPORTANCE\n",
            "====================================================================================================\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "                         feature  importance\n",
            "       solids_conductivity_ratio    0.186656\n",
            "                          Solids    0.151693\n",
            "      chloramines_ph_interaction    0.081712\n",
            "                     Chloramines    0.060089\n",
            "               turbidity_squared    0.053618\n",
            "                       Turbidity    0.053410\n",
            "sulfate_conductivity_interaction    0.043409\n",
            "               organic_thm_ratio    0.040465\n",
            "                         Sulfate    0.037886\n",
            "                   quality_score    0.037070\n",
            "\n",
            "Bottom 5 Least Important Features:\n",
            "                 feature  importance\n",
            "     Turbidity_compliant    0.000377\n",
            "   Chloramines_compliant    0.000283\n",
            "       Sulfate_compliant    0.000233\n",
            "        Solids_compliant    0.000006\n",
            "Organic_carbon_compliant    0.000000\n",
            "\n",
            "====================================================================================================\n",
            " SAVING TUNED MODEL \n",
            "====================================================================================================\n",
            "\n",
            " Tuned model saved to: models/random_forest_tuned_20260112_121216.joblib\n",
            "Grid search results saved to: models/grid_search_results_20260112_121217.joblib\n",
            "Tuning summary saved to: models/tuning_summary_20260112_121217.joblib\n",
            "\n",
            "====================================================================================================\n",
            "HYPERPARAMETER TUNING COMPLETE\n",
            "====================================================================================================\n",
            "\n",
            "RECOMMENDATION:\n",
            "  Tuned model tidak menunjukkan improvement\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# HYPERPARAMETER TUNING - RANDOM FOREST\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"HYPERPARAMETER TUNING - RANDOM FOREST\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Get the baseline model for reference\n",
        "baseline_model = baseline_results['Random Forest']['model']\n",
        "baseline_test_roc_auc = baseline_results['Random Forest']['test_roc_auc']\n",
        "baseline_cv_roc_auc = baseline_results['Random Forest']['cv_roc_auc_mean']\n",
        "\n",
        "print(f\"\\nBaseline Performance:\")\n",
        "print(f\"  CV ROC-AUC:   {baseline_cv_roc_auc:.4f}\")\n",
        "print(f\"  Test ROC-AUC: {baseline_test_roc_auc:.4f}\")\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [150, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_samples': [0.7, 0.8]\n",
        "}\n",
        "\n",
        "print(f\"\\nParameter Grid:\")\n",
        "print(f\"  n_estimators: {param_grid['n_estimators']}\")\n",
        "print(f\"  max_depth: {param_grid['max_depth']}\")\n",
        "print(f\"  min_samples_split: {param_grid['min_samples_split']}\")\n",
        "print(f\"  min_samples_leaf: {param_grid['min_samples_leaf']}\")\n",
        "print(f\"  max_features: {param_grid['max_features']}\")\n",
        "print(f\"  max_samples: {param_grid['max_samples']}\")\n",
        "\n",
        "# Calculate total combinations\n",
        "total_combinations = 1\n",
        "for param_values in param_grid.values():\n",
        "    total_combinations *= len(param_values)\n",
        "print(f\"\\nTotal parameter combinations: {total_combinations}\")\n",
        "print(f\"Total fits (5-fold CV): {total_combinations * 5}\")\n",
        "\n",
        "tuned_results = {}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        class_weight='balanced',\n",
        "        oob_score=True\n",
        "    ),\n",
        "    param_grid=param_grid,\n",
        "    cv=cv,  # Using the same StratifiedKFold\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Perform grid search\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "tuning_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nGrid Search completed in {tuning_time:.2f}s ({tuning_time/60:.2f} minutes)\")\n",
        "\n",
        "# ==============================================================================\n",
        "# BEST PARAMETERS AND RESULTS\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" TUNING RESULTS \")\n",
        "print(\"=\"*100)\n",
        "\n",
        "print(f\"\\nBest Parameters Found:\")\n",
        "for param, value in grid_search.best_params_.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "\n",
        "print(f\"\\nBest CV ROC-AUC: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Get the best model\n",
        "best_tuned_model = grid_search.best_estimator_\n",
        "\n",
        "# ==============================================================================\n",
        "# CALCULATE CV F1 SCORE\n",
        "# ==============================================================================\n",
        "print(f\"\\nCalculating CV F1 score...\")\n",
        "cv_f1_scores = cross_val_score(\n",
        "    best_tuned_model,\n",
        "    X_train_resampled,\n",
        "    y_train_resampled,\n",
        "    cv=cv,\n",
        "    scoring='f1_weighted',\n",
        "    n_jobs=-1\n",
        ")\n",
        "cv_f1_mean = cv_f1_scores.mean()\n",
        "cv_f1_std = cv_f1_scores.std()\n",
        "\n",
        "print(f\"  CV F1 (mean Â± std): {cv_f1_mean:.4f} Â± {cv_f1_std:.4f}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# EVALUATE ON TEST SET\n",
        "# ==============================================================================\n",
        "print(f\"\\nEvaluating tuned model on test set...\")\n",
        "y_pred_tuned = best_tuned_model.predict(X_test_processed)\n",
        "y_pred_proba_tuned = best_tuned_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "tuned_test_accuracy = accuracy_score(y_test, y_pred_tuned)\n",
        "tuned_test_precision = precision_score(y_test, y_pred_tuned, average='weighted', zero_division=0)\n",
        "tuned_test_recall = recall_score(y_test, y_pred_tuned, average='weighted', zero_division=0)\n",
        "tuned_test_f1 = f1_score(y_test, y_pred_tuned, average='weighted', zero_division=0)\n",
        "tuned_test_roc_auc = roc_auc_score(y_test, y_pred_proba_tuned)\n",
        "\n",
        "# Per-class metrics\n",
        "tuned_precision_class0 = precision_score(y_test, y_pred_tuned, pos_label=0, zero_division=0)\n",
        "tuned_recall_class0 = recall_score(y_test, y_pred_tuned, pos_label=0, zero_division=0)\n",
        "tuned_f1_class0 = f1_score(y_test, y_pred_tuned, pos_label=0, zero_division=0)\n",
        "\n",
        "tuned_precision_class1 = precision_score(y_test, y_pred_tuned, pos_label=1, zero_division=0)\n",
        "tuned_recall_class1 = recall_score(y_test, y_pred_tuned, pos_label=1, zero_division=0)\n",
        "tuned_f1_class1 = f1_score(y_test, y_pred_tuned, pos_label=1, zero_division=0)\n",
        "\n",
        "# OOB Score\n",
        "tuned_oob_score = best_tuned_model.oob_score_ if hasattr(best_tuned_model, 'oob_score_') else np.nan\n",
        "\n",
        "# ==============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ==============================================================================\n",
        "tuned_results['Random Forest'] = {\n",
        "    'model': best_tuned_model,\n",
        "    'best_params': grid_search.best_params_,\n",
        "    # CV metrics - consistent naming (no \"_mean\" suffix)\n",
        "    'cv_roc_auc': grid_search.best_score_,\n",
        "    'cv_f1': cv_f1_mean,\n",
        "    # Test metrics\n",
        "    'test_accuracy': tuned_test_accuracy,\n",
        "    'test_precision': tuned_test_precision,\n",
        "    'test_recall': tuned_test_recall,\n",
        "    'test_f1': tuned_test_f1,\n",
        "    'test_roc_auc': tuned_test_roc_auc,\n",
        "    # Additional metrics\n",
        "    'oob_score': tuned_oob_score,\n",
        "    'precision_class0': tuned_precision_class0,\n",
        "    'recall_class0': tuned_recall_class0,\n",
        "    'f1_class0': tuned_f1_class0,\n",
        "    'precision_class1': tuned_precision_class1,\n",
        "    'recall_class1': tuned_recall_class1,\n",
        "    'f1_class1': tuned_f1_class1,\n",
        "    'training_time': tuning_time,\n",
        "    'y_pred': y_pred_tuned,\n",
        "    'y_pred_proba': y_pred_proba_tuned\n",
        "}\n",
        "\n",
        "print(f\"\\nTuned Model Performance:\")\n",
        "print(f\"  CV ROC-AUC:     {grid_search.best_score_:.4f}\")\n",
        "print(f\"  CV F1:          {cv_f1_mean:.4f}\")\n",
        "print(f\"  Test Accuracy:  {tuned_test_accuracy:.4f}\")\n",
        "print(f\"  Test Precision: {tuned_test_precision:.4f}\")\n",
        "print(f\"  Test Recall:    {tuned_test_recall:.4f}\")\n",
        "print(f\"  Test F1:        {tuned_test_f1:.4f}\")\n",
        "print(f\"  Test ROC-AUC:   {tuned_test_roc_auc:.4f}\")\n",
        "print(f\"  OOB Score:      {tuned_oob_score:.4f}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# BASELINE VS TUNED COMPARISON\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" BASELINE VS TUNED MODEL COMPARISON \")\n",
        "print(\"=\"*100)\n",
        "\n",
        "comparison_table = pd.DataFrame({\n",
        "    'Metric': ['CV ROC-AUC', 'Test Accuracy', 'Test Precision', 'Test Recall',\n",
        "               'Test F1', 'Test ROC-AUC', 'OOB Score'],\n",
        "    'Baseline': [\n",
        "        f\"{baseline_cv_roc_auc:.4f}\",\n",
        "        f\"{baseline_results['Random Forest']['test_accuracy']:.4f}\",\n",
        "        f\"{baseline_results['Random Forest']['test_precision']:.4f}\",\n",
        "        f\"{baseline_results['Random Forest']['test_recall']:.4f}\",\n",
        "        f\"{baseline_results['Random Forest']['test_f1']:.4f}\",\n",
        "        f\"{baseline_test_roc_auc:.4f}\",\n",
        "        f\"{baseline_model.oob_score_:.4f}\" if hasattr(baseline_model, 'oob_score_') else 'N/A'\n",
        "    ],\n",
        "    'Tuned': [\n",
        "        f\"{grid_search.best_score_:.4f}\",\n",
        "        f\"{tuned_test_accuracy:.4f}\",\n",
        "        f\"{tuned_test_precision:.4f}\",\n",
        "        f\"{tuned_test_recall:.4f}\",\n",
        "        f\"{tuned_test_f1:.4f}\",\n",
        "        f\"{tuned_test_roc_auc:.4f}\",\n",
        "        f\"{tuned_oob_score:.4f}\" if not np.isnan(tuned_oob_score) else 'N/A'\n",
        "    ],\n",
        "    'Improvement': [\n",
        "        f\"{(grid_search.best_score_ - baseline_cv_roc_auc):.4f}\",\n",
        "        f\"{(tuned_test_accuracy - baseline_results['Random Forest']['test_accuracy']):.4f}\",\n",
        "        f\"{(tuned_test_precision - baseline_results['Random Forest']['test_precision']):.4f}\",\n",
        "        f\"{(tuned_test_recall - baseline_results['Random Forest']['test_recall']):.4f}\",\n",
        "        f\"{(tuned_test_f1 - baseline_results['Random Forest']['test_f1']):.4f}\",\n",
        "        f\"{(tuned_test_roc_auc - baseline_test_roc_auc):.4f}\",\n",
        "        f\"{(tuned_oob_score - baseline_model.oob_score_):.4f}\" if hasattr(baseline_model, 'oob_score_') else 'N/A'\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\n\", comparison_table.to_string(index=False))\n",
        "\n",
        "# ==============================================================================\n",
        "# PER-CLASS PERFORMANCE COMPARISON\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" PER-CLASS PERFORMANCE COMPARISON \")\n",
        "print(\"=\"*100)\n",
        "\n",
        "per_class_comparison = pd.DataFrame({\n",
        "    'Class': ['Not Potable (0)', 'Not Potable (0)', 'Not Potable (0)',\n",
        "              'Potable (1)', 'Potable (1)', 'Potable (1)'],\n",
        "    'Metric': ['Precision', 'Recall', 'F1-Score', 'Precision', 'Recall', 'F1-Score'],\n",
        "    'Baseline': [\n",
        "        f\"{baseline_results['Random Forest']['precision_class0']:.4f}\",\n",
        "        f\"{baseline_results['Random Forest']['recall_class0']:.4f}\",\n",
        "        f\"{baseline_results['Random Forest']['f1_class0']:.4f}\",\n",
        "        f\"{baseline_results['Random Forest']['precision_class1']:.4f}\",\n",
        "        f\"{baseline_results['Random Forest']['recall_class1']:.4f}\",\n",
        "        f\"{baseline_results['Random Forest']['f1_class1']:.4f}\"\n",
        "    ],\n",
        "    'Tuned': [\n",
        "        f\"{tuned_precision_class0:.4f}\",\n",
        "        f\"{tuned_recall_class0:.4f}\",\n",
        "        f\"{tuned_f1_class0:.4f}\",\n",
        "        f\"{tuned_precision_class1:.4f}\",\n",
        "        f\"{tuned_recall_class1:.4f}\",\n",
        "        f\"{tuned_f1_class1:.4f}\"\n",
        "    ],\n",
        "    'Improvement': [\n",
        "        f\"{(tuned_precision_class0 - baseline_results['Random Forest']['precision_class0']):.4f}\",\n",
        "        f\"{(tuned_recall_class0 - baseline_results['Random Forest']['recall_class0']):.4f}\",\n",
        "        f\"{(tuned_f1_class0 - baseline_results['Random Forest']['f1_class0']):.4f}\",\n",
        "        f\"{(tuned_precision_class1 - baseline_results['Random Forest']['precision_class1']):.4f}\",\n",
        "        f\"{(tuned_recall_class1 - baseline_results['Random Forest']['recall_class1']):.4f}\",\n",
        "        f\"{(tuned_f1_class1 - baseline_results['Random Forest']['f1_class1']):.4f}\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\n\", per_class_comparison.to_string(index=False))\n",
        "\n",
        "# ==============================================================================\n",
        "# DETAILED CLASSIFICATION REPORT\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" TUNED MODEL - CLASSIFICATION REPORT \")\n",
        "print(\"=\"*100)\n",
        "\n",
        "print(\"\\n\", classification_report(y_test, y_pred_tuned,\n",
        "                                  target_names=['Not Potable', 'Potable'],\n",
        "                                  digits=4))\n",
        "\n",
        "# ==============================================================================\n",
        "# TOP PARAMETER COMBINATIONS\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" TOP 10 PARAMETER COMBINATIONS \")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Get CV results\n",
        "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
        "cv_results = cv_results.sort_values('rank_test_score')\n",
        "\n",
        "# Select relevant columns\n",
        "top_params = cv_results[['rank_test_score', 'mean_test_score', 'std_test_score',\n",
        "                         'param_n_estimators', 'param_max_depth', 'param_min_samples_split',\n",
        "                         'param_min_samples_leaf', 'param_max_features', 'param_max_samples']].head(10)\n",
        "\n",
        "print(\"\\n\", top_params.to_string(index=False))\n",
        "\n",
        "# ==============================================================================\n",
        "# FEATURE IMPORTANCE\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" FEATURE IMPORTANCE\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "def get_processed_feature_names(preprocessor, input_df_columns):\n",
        "    output_feature_names = []\n",
        "    for name, transformer, features_orig in preprocessor.transformers_:\n",
        "        if transformer == 'passthrough':\n",
        "            output_feature_names.extend(features_orig)\n",
        "        elif hasattr(transformer, 'get_feature_names_out'):\n",
        "            if isinstance(transformer, OneHotEncoder):\n",
        "                output_feature_names.extend(transformer.get_feature_names_out(features_orig))\n",
        "            else:\n",
        "                output_feature_names.extend(features_orig)\n",
        "        else:\n",
        "            output_feature_names.extend(features_orig)\n",
        "    return output_feature_names\n",
        "\n",
        "if hasattr(best_tuned_model, 'feature_importances_'):\n",
        "    feature_names_tuned = get_processed_feature_names(preprocessor, X_train_complete.columns)\n",
        "\n",
        "    tuned_feature_importance = pd.DataFrame({\n",
        "        'feature': feature_names_tuned,\n",
        "        'importance': best_tuned_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(f\"\\nTop 10 Most Important Features:\")\n",
        "    print(tuned_feature_importance.head(10).to_string(index=False))\n",
        "\n",
        "    print(f\"\\nBottom 5 Least Important Features:\")\n",
        "    print(tuned_feature_importance.tail(5).to_string(index=False))\n",
        "\n",
        "# ==============================================================================\n",
        "# SAVE TUNED MODEL\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" SAVING TUNED MODEL \")\n",
        "print(\"=\"*100)\n",
        "\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Save the tuned model\n",
        "model_filename = f'models/random_forest_tuned_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.joblib'\n",
        "joblib.dump(best_tuned_model, model_filename)\n",
        "print(f\"\\n Tuned model saved to: {model_filename}\")\n",
        "\n",
        "# Save grid search results\n",
        "grid_results_filename = f'models/grid_search_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.joblib'\n",
        "joblib.dump(grid_search, grid_results_filename)\n",
        "print(f\"Grid search results saved to: {grid_results_filename}\")\n",
        "\n",
        "# Save comparison summary\n",
        "summary = {\n",
        "    'baseline_performance': {\n",
        "        'cv_roc_auc': baseline_cv_roc_auc,\n",
        "        'test_roc_auc': baseline_test_roc_auc,\n",
        "        'test_f1': baseline_results['Random Forest']['test_f1']\n",
        "    },\n",
        "    'tuned_performance': {\n",
        "        'cv_roc_auc': grid_search.best_score_,\n",
        "        'cv_f1': cv_f1_mean,\n",
        "        'test_roc_auc': tuned_test_roc_auc,\n",
        "        'test_f1': tuned_test_f1\n",
        "    },\n",
        "    'best_params': grid_search.best_params_,\n",
        "    'improvement': {\n",
        "        'cv_roc_auc': grid_search.best_score_ - baseline_cv_roc_auc,\n",
        "        'test_roc_auc': tuned_test_roc_auc - baseline_test_roc_auc,\n",
        "        'test_f1': tuned_test_f1 - baseline_results['Random Forest']['test_f1']\n",
        "    }\n",
        "}\n",
        "\n",
        "summary_filename = f'models/tuning_summary_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.joblib'\n",
        "joblib.dump(summary, summary_filename)\n",
        "print(f\"Tuning summary saved to: {summary_filename}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"HYPERPARAMETER TUNING COMPLETE\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Final recommendation\n",
        "print(f\"\\nRECOMMENDATION:\")\n",
        "if tuned_test_roc_auc > baseline_test_roc_auc:\n",
        "    improvement_pct = ((tuned_test_roc_auc - baseline_test_roc_auc) / baseline_test_roc_auc) * 100\n",
        "    print(f\"  Use TUNED model - improved  {improvement_pct:.2f}%\")\n",
        "    print(f\"  Test ROC-AUC: {baseline_test_roc_auc:.4f} â {tuned_test_roc_auc:.4f}\")\n",
        "else:\n",
        "    print(f\"  Tuned model tidak menunjukkan improvement\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtY66XZN_hDS"
      },
      "source": [
        "#PHASE 6: EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3Zd7IsRRAuDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d826a4c-84b3-4a0e-cd89-1ddb4c45ca3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "\n",
            " BEST TUNED MODEL: Random Forest\n",
            "   CV ROC-AUC:     0.9536\n",
            "   CV F1:          0.8812\n",
            "   Test ROC-AUC:   0.9337\n",
            "   Test F1:        0.8488\n",
            "   Test Accuracy:  0.8490\n",
            "\n",
            " Best Parameters:\n",
            "   max_depth: None\n",
            "   max_features: sqrt\n",
            "   max_samples: 0.8\n",
            "   min_samples_leaf: 1\n",
            "   min_samples_split: 5\n",
            "   n_estimators: 200\n",
            "\n",
            "   AVERAGE IMPROVEMENT (All 1 Models):\n",
            "\n",
            "   ROC-AUC:\n",
            "      Baseline avg: 0.9345\n",
            "      Tuned avg:    0.9337\n",
            "      Improvement:  -0.09%\n",
            "\n",
            "   F1-Score:\n",
            "      Baseline avg: 0.8487\n",
            "      Tuned avg:    0.8488\n",
            "      Improvement:  +0.01%\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "# print(\" FINAL SUMMARY \".center(100))\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Check if tuned_results is defined\n",
        "if 'tuned_results' not in globals():\n",
        "    print(\"Error: 'tuned_results' is not defined.\")\n",
        "else:\n",
        "    # Best tuned model\n",
        "    best_tuned_model = max(tuned_results.keys(), key=lambda k: tuned_results[k]['test_roc_auc'])\n",
        "    best_tuned_auc = tuned_results[best_tuned_model]['test_roc_auc']\n",
        "\n",
        "    print(f\"\\n BEST TUNED MODEL: {best_tuned_model}\")\n",
        "    print(f\"   CV ROC-AUC:     {tuned_results[best_tuned_model]['cv_roc_auc']:.4f}\")\n",
        "    print(f\"   CV F1:          {tuned_results[best_tuned_model]['cv_f1']:.4f}\")\n",
        "    print(f\"   Test ROC-AUC:   {best_tuned_auc:.4f}\")\n",
        "    print(f\"   Test F1:        {tuned_results[best_tuned_model]['test_f1']:.4f}\")\n",
        "    print(f\"   Test Accuracy:  {tuned_results[best_tuned_model]['test_accuracy']:.4f}\")\n",
        "\n",
        "    print(f\"\\n Best Parameters:\")\n",
        "    for param, value in tuned_results[best_tuned_model]['best_params'].items():\n",
        "        print(f\"   {param}: {value}\")\n",
        "\n",
        "    # Average improvement\n",
        "    baseline_auc_avg = np.mean([baseline_results[m]['test_roc_auc'] for m in tuned_results.keys()])\n",
        "    tuned_auc_avg = np.mean([tuned_results[m]['test_roc_auc'] for m in tuned_results.keys()])\n",
        "    improvement_auc = ((tuned_auc_avg - baseline_auc_avg) / baseline_auc_avg) * 100\n",
        "\n",
        "    baseline_f1_avg = np.mean([baseline_results[m]['test_f1'] for m in tuned_results.keys()])\n",
        "    tuned_f1_avg = np.mean([tuned_results[m]['test_f1'] for m in tuned_results.keys()])\n",
        "    improvement_f1 = ((tuned_f1_avg - baseline_f1_avg) / baseline_f1_avg) * 100\n",
        "\n",
        "    print(f\"\\n   AVERAGE IMPROVEMENT (All {len(tuned_results)} Models):\")\n",
        "    print(f\"\\n   ROC-AUC:\")\n",
        "    print(f\"      Baseline avg: {baseline_auc_avg:.4f}\")\n",
        "    print(f\"      Tuned avg:    {tuned_auc_avg:.4f}\")\n",
        "    print(f\"      Improvement:  {improvement_auc:+.2f}%\")\n",
        "    print(f\"\\n   F1-Score:\")\n",
        "    print(f\"      Baseline avg: {baseline_f1_avg:.4f}\")\n",
        "    print(f\"      Tuned avg:    {tuned_f1_avg:.4f}\")\n",
        "    print(f\"      Improvement:  {improvement_f1:+.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH8ujA69d7HJ"
      },
      "source": [
        "# PHASE 7: DEPLOYMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ufv8DtrzLpzk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ee1501e9-4da7-4842-b9d0-85ee48c2abf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "                          SAVING MODEL FOR DEPLOYMENT                           \n",
            "================================================================================\n",
            "\n",
            " Model saved: random_forest_model.pkl\n",
            " Preprocessor saved: preprocessor(2).pkl\n",
            "\n",
            " Downloading files to your computer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_55577474-3bb7-4381-85ee-001d18ca8e35\", \"random_forest_model.pkl\", 15575094)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0db521a0-ed36-4e71-b070-49727b091c78\", \"preprocessor(2).pkl\", 7225)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" SAVING MODEL FOR DEPLOYMENT \".center(80))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save model\n",
        "best_model = tuned_results['Random Forest']['model']\n",
        "joblib.dump(best_model, 'random_forest_model.pkl')\n",
        "print(\"\\n Model saved: random_forest_model.pkl\")\n",
        "\n",
        "# Save preprocessor\n",
        "joblib.dump(preprocessor, 'preprocessor(2).pkl')\n",
        "print(\" Preprocessor saved: preprocessor(2).pkl\")\n",
        "\n",
        "# Download\n",
        "print(\"\\n Downloading files to your computer...\")\n",
        "files.download('random_forest_model.pkl')\n",
        "files.download('preprocessor(2).pkl')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}